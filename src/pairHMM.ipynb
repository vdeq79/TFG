{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from hmmlearn import hmm\n",
    "from scipy import special"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PairHMM(hmm.CategoricalHMM):\n",
    "    def __init__ (self, alphabet, mu, epsilon, tau, match_probabilities, insert_probabilities):\n",
    "\n",
    "        #Transformamos el alfabeto a una lista de caracteres\n",
    "        alphabet = list(map(str, alphabet))\n",
    "        self.alphabet = alphabet\n",
    "        self.n_alphabet = len(alphabet)\n",
    "\n",
    "        #Calculamos el número de posibles emisiones a partir del alfabeto\n",
    "        n_features = self.n_alphabet**2+2*self.n_alphabet+1\n",
    "\n",
    "        #Los cinco estados son (Begin, M, X, Y, End)\n",
    "        super().__init__(n_components=5, n_features=n_features)\n",
    "\n",
    "        #Calculamos las probabilidades a partir de los parámetros\n",
    "        match_to_ins = np.subtract(1.0, 2.0*mu+tau)\n",
    "        ins_to_match = np.subtract(1.0, epsilon+tau)\n",
    "\n",
    "        if match_to_ins<0.0 :\n",
    "            raise ValueError(f\"1-2*mu-tau debe ser no negativo (se ha obtenido {match_to_ins:.4f})\")\n",
    "\n",
    "        if ins_to_match<0.0 :\n",
    "            raise ValueError(f\"1-epsilon-tau debe ser no negativo (se ha obtenido {ins_to_match:.4f})\")\n",
    "\n",
    "        self.transmat_  = np.array([[0,match_to_ins, mu, mu, tau], \n",
    "                                   [0,match_to_ins, mu, mu, tau],\n",
    "                                   [0,ins_to_match, epsilon, 0, tau],\n",
    "                                   [0,ins_to_match, 0, epsilon, tau],\n",
    "                                   [0,0,0,0,1]]) \n",
    "        \n",
    "        self.__init_emissions(match_probabilities, insert_probabilities)\n",
    "\n",
    "\n",
    "    def __init_emissions(self, match_probabilities, insert_probabilities):\n",
    "        self.emissionprob_ = np.zeros((5, self.n_features))\n",
    "\n",
    "        #Emisiones de estados silenciosos\n",
    "        self.emissionprob_[0,self.n_features-1] = 1\n",
    "        self.emissionprob_[4,self.n_features-1] = 1\n",
    "\n",
    "        if len(match_probabilities)!=(self.n_alphabet**2):\n",
    "            raise ValueError(f\"El número de emisiones en el estado de alineamiento debe ser {self.n_alphabet**2})\")\n",
    "        \n",
    "        if len(insert_probabilities)!=(self.n_alphabet):\n",
    "            raise ValueError(f\"El número de emisiones en el estado de inserción debe ser {self.n_alphabet})\")\n",
    "        \n",
    "        self.emissionprob_[1, 0:self.n_alphabet**2] = match_probabilities\n",
    "        self.emissionprob_[2, self.n_alphabet**2: self.n_alphabet**2+self.n_alphabet] = insert_probabilities\n",
    "        self.emissionprob_[3, self.n_alphabet**2+self.n_alphabet:self.n_features-1] = insert_probabilities\n",
    "        self.startprob_=np.array([1,0,0,0,0])\n",
    "        self._check()\n",
    "\n",
    "    #Función que convierte una secuencia de elementos del alfabeto en secuencia de índices \n",
    "    def __decodify(self, x):\n",
    "        x = list(map(str.upper, x))\n",
    "        try:\n",
    "            decoded= np.array(list(map(self.alphabet.index, x)))\n",
    "        except ValueError:\n",
    "            print(\"¡Error, existe elemento de la secuencia que no se encuentra en el alfabeto!\")\n",
    "            raise\n",
    "        return decoded\n",
    "    \n",
    "    #Función que construye el alineamiento a partir de secuencia de estados\n",
    "    def __codify(self,state_sequence,x,y):\n",
    "        i=0\n",
    "        j=0\n",
    "        align1 = []\n",
    "        align2 = []\n",
    "        for k in state_sequence:\n",
    "            match k:\n",
    "                case 0:\n",
    "                    align1.append(x[i])\n",
    "                    align2.append(y[j])\n",
    "                    i+=1\n",
    "                    j+=1\n",
    "                case 1:\n",
    "                    align1.append(x[i])\n",
    "                    align2.append(\"-\")\n",
    "                    i+=1\n",
    "                case 2:\n",
    "                    align1.append(\"-\")\n",
    "                    align2.append(y[j])\n",
    "                    j+=1\n",
    "\n",
    "        return \"\".join(align1), \"\".join(align2)\n",
    "\n",
    "    #Función \n",
    "    def modifiedViterbi(self, x, y):\n",
    "\n",
    "        decoded_x = self.__decodify(x)\n",
    "        decoded_y = self.__decodify(y)\n",
    "\n",
    "        #Tendremos valores de (0,0) a (n,m)\n",
    "        n = len(decoded_x)\n",
    "        m = len(decoded_y)\n",
    "\n",
    "        v = np.zeros((3, n+1, m+1))\n",
    "        pointer = np.zeros((3, n+1, m+1), dtype=int)\n",
    "        v[0,0,0] = 1\n",
    "        \n",
    "        #Ignorar el warning de división entre 0 a la hora de calcular log(0)\n",
    "        with np.errstate(divide='ignore'): \n",
    "            #Inicializar las variables\n",
    "            log_emissionprob_ =  np.log(self.emissionprob_)\n",
    "            log_transmat_ = np.log(self.transmat_)\n",
    "            v = np.log(v)\n",
    "        \n",
    "\n",
    "        for i in range(1,n+1):\n",
    "            v[1,i,0] = log_emissionprob_[2,(self.n_alphabet**2)+decoded_x[i-1]]+np.max([log_transmat_[1,2]+v[0,i-1,0], log_transmat_[2,2]+v[1,i-1,0] ])\n",
    "            pointer[1,i,0] = np.argmax([log_transmat_[1,2]+v[0,i-1,0], log_transmat_[2,2]+v[1,i-1,0], -np.inf ])\n",
    "\n",
    "        for j in range(1,m+1):\n",
    "            v[2,0,j] = log_emissionprob_[3,(self.n_alphabet**2+self.n_alphabet)+decoded_y[j-1]]+np.max([log_transmat_[1,3]+v[0,0,j-1], log_transmat_[3,3]+v[2,0,j-1] ])\n",
    "            pointer[2,0,j] = np.argmax([log_transmat_[1,3]+v[0,0,j-1], -np.inf ,log_transmat_[3,3]+v[2,0,j-1] ])\n",
    "\n",
    "        for i in range(1,n+1):\n",
    "            for j in range(1,m+1):\n",
    "                v[0,i,j] = log_emissionprob_[1,decoded_x[i-1]*self.n_alphabet+decoded_y[j-1]]+np.max([log_transmat_[1,1]+v[0,i-1,j-1], log_transmat_[2,1]+v[1,i-1,j-1], log_transmat_[3,1]+v[2,i-1,j-1] ])\n",
    "                pointer[0,i,j] = np.argmax([log_transmat_[1,1]+v[0,i-1,j-1], log_transmat_[2,1]+v[1,i-1,j-1], log_transmat_[3,1]+v[2,i-1,j-1] ])\n",
    "\n",
    "                v[1,i,j] = log_emissionprob_[2,(self.n_alphabet**2)+decoded_x[i-1]]+np.max([log_transmat_[1,2]+v[0,i-1,j], log_transmat_[2,2]+v[1,i-1,j] ])\n",
    "                pointer[1,i,j] = np.argmax([log_transmat_[1,2]+v[0,i-1,j], log_transmat_[2,2]+v[1,i-1,j], -np.inf ])\n",
    "\n",
    "                v[2,i,j] = log_emissionprob_[3,(self.n_alphabet**2+self.n_alphabet)+decoded_y[j-1]]+np.max([log_transmat_[1,3]+v[0,i,j-1], log_transmat_[3,3]+v[2,i,j-1] ])\n",
    "                pointer[2,i,j] = np.argmax([log_transmat_[1,3]+v[0,i,j-1], -np.inf ,log_transmat_[3,3]+v[2,i,j-1] ])\n",
    "\n",
    "        #Empezamos el proceso de recuperación de estados\n",
    "        sequence = [ np.argmax([v[0,n,m], v[1,n,m], v[2,n,m] ])]\n",
    "        i = n\n",
    "        j = m\n",
    "        \n",
    "        #Los índices cambiarán dependiendo del último estado\n",
    "        def cases(state, i, j):            \n",
    "            if i>0 and (state==0 or state==1):\n",
    "                i-=1\n",
    "            if j>0 and (state==0 or state==2):\n",
    "                j-=1\n",
    "            return i,j\n",
    "\n",
    "        while i>0 or j>0:\n",
    "            next_state = pointer[sequence[-1] ,i,j]\n",
    "            i,j = cases(sequence[-1],i,j) \n",
    "            sequence.append( next_state )\n",
    "\n",
    "        #Eliminamos el último elemento pues es siempre el estado inicial\n",
    "        del sequence[-1]\n",
    "\n",
    "        #Invertimos para obtener la secuencia de estados\n",
    "        sequence.reverse()\n",
    "        return sequence, self.__codify(sequence,x,y), self.transmat_[0,4]*np.max(np.exp([v[0,n,m], v[1,n,m], v[2,n,m]]))\n",
    "    \n",
    "\n",
    "    def modifiedFoward(self, x, y):\n",
    "\n",
    "        decoded_x = self.__decodify(x)\n",
    "        decoded_y = self.__decodify(y)\n",
    "\n",
    "        #Tendremos valores de (0,0) a (n,m)\n",
    "        n = len(decoded_x)\n",
    "        m = len(decoded_y)\n",
    "\n",
    "        v = np.zeros((3, n+1, m+1))\n",
    "        v[0,0,0] = 1\n",
    "\n",
    "        #Ignorar el warning de división entre 0 a la hora de calcular log(0)\n",
    "        with np.errstate(divide='ignore'): \n",
    "            #Inicializar las variables\n",
    "            log_emissionprob_ =  np.log(self.emissionprob_)\n",
    "            log_transmat_ = np.log(self.transmat_)\n",
    "            v = np.log(v)\n",
    "\n",
    "\n",
    "        for i in range(1,n+1):\n",
    "            v[1,i,0] = log_emissionprob_[2,(self.n_alphabet**2)+decoded_x[i-1]]+special.logsumexp([log_transmat_[1,2]+v[0,i-1,0], log_transmat_[2,2]+v[1,i-1,0] ])\n",
    "\n",
    "        for j in range(1,m+1):\n",
    "            v[2,0,j] = log_emissionprob_[3,(self.n_alphabet**2+self.n_alphabet)+decoded_y[j-1]]+special.logsumexp([log_transmat_[1,3]+v[0,0,j-1], log_transmat_[3,3]+v[2,0,j-1] ])\n",
    "            \n",
    "        for i in range(1,n+1):\n",
    "            for j in range(1,m+1):\n",
    "                v[0,i,j] = log_emissionprob_[1,decoded_x[i-1]*self.n_alphabet+decoded_y[j-1]]+special.logsumexp([log_transmat_[1,1]+v[0,i-1,j-1], log_transmat_[2,1]+v[1,i-1,j-1], log_transmat_[3,1]+v[2,i-1,j-1] ])\n",
    "\n",
    "                v[1,i,j] = log_emissionprob_[2,(self.n_alphabet**2)+decoded_x[i-1]]+special.logsumexp([log_transmat_[1,2]+v[0,i-1,j], log_transmat_[2,2]+v[1,i-1,j] ])\n",
    "\n",
    "                v[2,i,j] = log_emissionprob_[3,(self.n_alphabet**2+self.n_alphabet)+decoded_y[j-1]]+special.logsumexp([log_transmat_[1,3]+v[0,i,j-1], log_transmat_[3,3]+v[2,i,j-1] ])\n",
    "\n",
    "        return self.transmat_[0,4]*np.sum(np.exp([v[0,n,m], v[1,n,m], v[2,n,m]]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejemplos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PairHMM(alphabet=[\"A\", \"C\", \"G\", \"T\"], mu=0.2, epsilon=0.3, tau=0.1, match_probabilities=[0.2, 0.0125, 0.0125, 0.025, 0.0125, 0.2, 0.025, 0.0125, 0.0125, 0.025, 0.2, 0.0125, 0.025, 0.0125, 0.0125, 0.2], insert_probabilities=[0.25]*4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=\"CACGAAT\"\n",
    "y=\"AGTTCAA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CA---CGAAT\n",
      "-AGTTC-AA-\n"
     ]
    }
   ],
   "source": [
    "sequence, alignment, p_fin=model.modifiedViterbi( x, y )\n",
    "print(\"\\n\".join(alignment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.85602525347472e-12\n"
     ]
    }
   ],
   "source": [
    "total_prob=model.modifiedFoward(x, y)\n",
    "print(total_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10373930673190596\n"
     ]
    }
   ],
   "source": [
    "p_sequence = p_fin/total_prob\n",
    "print(p_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAAAAAA\n",
      "AAAAAAA\n",
      "2.8039432167959317e-08\n"
     ]
    }
   ],
   "source": [
    "sequence, alignment, p_fin=model.modifiedViterbi( \"AAAAAAA\" , \"AAAAAAA\" )\n",
    "print(\"\\n\".join(alignment))\n",
    "total_prob=model.modifiedFoward(\"AAAAAAA\", \"AAAAAAA\")\n",
    "print(total_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PairHMM(alphabet=[\"A\", \"C\", \"G\", \"T\"], mu=0.2, epsilon=0.5, tau=0.1, match_probabilities=[0.2, 0.0125, 0.0125, 0.025, 0.0125, 0.2, 0.025, 0.0125, 0.0125, 0.025, 0.2, 0.0125, 0.025, 0.0125, 0.0125, 0.2], insert_probabilities=[0.25]*4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CACG---AAT\n",
      "-A-GTTCAA-\n"
     ]
    }
   ],
   "source": [
    "sequence, alignment, p_fin=model.modifiedViterbi( x, y )\n",
    "print(\"\\n\".join(alignment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.758812258839653e-12\n",
      "0.08682345899234942\n"
     ]
    }
   ],
   "source": [
    "total_prob=model.modifiedFoward(x, y)\n",
    "print(total_prob)\n",
    "p_sequence = p_fin/total_prob\n",
    "print(p_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PairHMM([\"A\", \"C\", \"G\", \"T\"], 0.1, 0.1, 0.1, [0.125, 0.0375, 0.0125, 0.075, 0.0375, 0.125, 0.075, 0.0125, 0.0125, 0.075, 0.125, 0.0375, 0.075, 0.0125, 0.0375, 0.125], [0.25]*4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=\"TTTAACTTATCG\"\n",
    "y=\"TTACTCG\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TTTAACTTATCG\n",
      "-TT-AC-T--CG\n"
     ]
    }
   ],
   "source": [
    "sequence, alignment, p_fin=model.modifiedViterbi( x, y )\n",
    "print(\"\\n\".join(alignment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.8758596420364025e-15"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.modifiedFoward(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PairHMM([\"A\", \"C\", \"G\", \"T\"], 0.1, 0.1, 0.02, [0.125, 0.0375, 0.0125, 0.075, 0.0375, 0.125, 0.075, 0.0125, 0.0125, 0.075, 0.125, 0.0375, 0.075, 0.0125, 0.0375, 0.125], [0.25]*4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=\"gcgcgtgcgcggaaggagccaaggtgaagttgtagcagtgtgtcagaagaggtgcgtggcaccatgctgtcccccgaggcggagcgggtgctgcggtacctggtcgaagtagaggagttg\"\n",
    "y=\"gacttgtggaacctacttcctgaaaataaccttctgtcctccgagctctccgcacccgtggatgacctgctcccgtacacagatgttgccacctggctggatgaatgtccgaatgaagcg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gcgcgtgcgcggaaggagccaaggtgaagttgtagcagtgtgtcagaagaggtgcgtggcacca-tgctgtcccccgaggcggagcgggtgctgcggtacctgg-tcgaagta-ga-gg-a-gtt--g\n",
      "ga-cttg-t-ggaacct-acttcctgaa-aataacct-tctgtcctccgagctctc-cgcacccgtggatgacctgctcccgtacacagatgttgcc-acctggctggatgaatgtccgaatgaagcg\n"
     ]
    }
   ],
   "source": [
    "sequence, alignment, p_fin=model.modifiedViterbi( x, y )\n",
    "print(\"\\n\".join(alignment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.859574024341285e-150"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.modifiedFoward(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PairHMM([\"A\", \"C\", \"G\", \"T\"], 0.2, 0.1, 0.1, [0.125, 0.0375, 0.0125, 0.075 , 0.0375, 0.125, 0.075, 0.0125, 0.0125, 0.075, 0.125, 0.0375, 0.075, 0.0125, 0.0375, 0.125], [0.25]*4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=\"TTACG\"\n",
    "y=\"TAG\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TTACG\n",
      "-TA-G\n"
     ]
    }
   ],
   "source": [
    "sequence, alignment, p_fin=model.modifiedViterbi( x, y )\n",
    "print(\"\\n\".join(alignment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.712099609375e-07"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.modifiedFoward(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=\"TACGAACTG\"\n",
    "y=\"TCGTAACGTA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TACG-AAC-TG\n",
      "T-CGTAACGTA\n"
     ]
    }
   ],
   "source": [
    "sequence, alignment, p_fin=model.modifiedViterbi( x, y )\n",
    "print(\"\\n\".join(alignment))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
