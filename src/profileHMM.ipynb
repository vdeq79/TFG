{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from hmmlearn import hmm\n",
    "from enum import Enum   \n",
    "from scipy import special"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Declaración de enumerado para distinguir los estados\n",
    "class states(Enum):\n",
    "    M = 0\n",
    "    D = 1\n",
    "    I = 2\n",
    "    I_gap = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProfileHMM(hmm.CategoricalHMM):\n",
    "    def __init__(self, alphabet, gap_symbol ,alignment, insertion_criteria=None, emission_pseudocounts=None , transition_pseudocounts=None, show_probabilities = False):\n",
    "\n",
    "        #Transformamos el alfabeto a una lista de caracteres\n",
    "        alphabet = list(map(str, alphabet))\n",
    "        self.alphabet = alphabet\n",
    "        self.gap = gap_symbol\n",
    "\n",
    "        #Añadimos como posibles emisiones el gap y la emisión silenciosa\n",
    "        n_features = len(alphabet) + 2\n",
    "\n",
    "        #Obtener la longitud de las secuencias\n",
    "        sequence_length = len(alignment[0])\n",
    "\n",
    "        if not all(c in alphabet or c==gap_symbol for c in \"\".join(alignment)):\n",
    "            raise ValueError(\"Existen caracteres en el alineamiento que no se encuentran en el alfabeto\")\n",
    "\n",
    "        #Comprobar que todas las secuencias tienen la misma longitud\n",
    "        if not all(len(seq) == sequence_length for seq in alignment):\n",
    "            raise ValueError(\"Todos las secuencias deben tener la misma longitud\")\n",
    "\n",
    "        #Obtener las regiones\n",
    "        regions = [\"\".join( [seq[i] for seq in alignment] ) for i in range(sequence_length)]\n",
    "        \n",
    "        #Si no se introduce un criterio de inserción, se utiliza el por defecto\n",
    "        if not callable(insertion_criteria):\n",
    "            insert_regions = list(map(self.__default_insertion_criteria, regions))\n",
    "        else:\n",
    "            insert_regions = list(map(insertion_criteria, regions))\n",
    "        \n",
    "        #El número de estados de alineamiento es la suma de las regiones de alineamiento\n",
    "        self.n_match_states = insert_regions.count(False)\n",
    "\n",
    "        super().__init__(n_components=3*self.n_match_states+3, n_features=n_features)\n",
    "        self.startprob_ = np.zeros(self.n_components)\n",
    "        self.startprob_[0] = 1\n",
    "        self.transmat_ = np.zeros((self.n_components, self.n_components))\n",
    "        self.emissionprob_ = np.zeros((self.n_components, self.n_features))\n",
    "\n",
    "        match_emissions_pr, insert_emissions_pr, transition_pr, final_pr = self.__compute_probabilities(alignment, regions, insert_regions, emission_pseudocounts, transition_pseudocounts)\n",
    "\n",
    "        if (show_probabilities):\n",
    "            print(\"Probabilidades de emisión de estados de alineamiento:\\n\",match_emissions_pr)\n",
    "            print(\"Probabilidades de emisión de estados de inserción:\\n\", insert_emissions_pr)\n",
    "            print(\"Probabilidades de transición entre estados:\\n\", transition_pr)\n",
    "            print(\"Probabilidades de transición al estado fin:\\n\", final_pr)\n",
    "\n",
    "        self.emissionprob_[0, -1] = 1\n",
    "        self.emissionprob_[-1, -1] = 1\n",
    "        self.emissionprob_[1:self.n_match_states+1, 0:len(self.alphabet)] = match_emissions_pr\n",
    "        self.emissionprob_[self.n_match_states+1: 2*self.n_match_states+1, -2] = 1\n",
    "        self.emissionprob_[2*self.n_match_states+1:self.n_components-1,0:len(self.alphabet)] = insert_emissions_pr\n",
    "\n",
    "\n",
    "        current_positions = np.array([0, self.n_match_states, 2*self.n_match_states+1])\n",
    "        columns = np.array([0, self.n_match_states, 2*self.n_match_states]) + 1\n",
    "\n",
    "        for i in range(self.n_match_states):\n",
    "            \n",
    "            self.transmat_[current_positions[0], columns] = transition_pr[0,:,i]\n",
    "            if i>0:\n",
    "                self.transmat_[current_positions[1], columns] = transition_pr[1,:,i]\n",
    "            self.transmat_[current_positions[2], columns] = transition_pr[2,:,i]\n",
    "\n",
    "            current_positions = current_positions + 1\n",
    "            columns = columns + 1\n",
    "\n",
    "        self.transmat_[current_positions[0], [self.n_components-1, self.n_components-2] ] = final_pr[0]\n",
    "        self.transmat_[current_positions[1], [self.n_components-1, self.n_components-2] ] = final_pr[1]\n",
    "        self.transmat_[current_positions[2], [self.n_components-1, self.n_components-2] ] = final_pr[2]\n",
    "        self.transmat_[-1,-1] = 1\n",
    "\n",
    "\n",
    "    #Función que convierte una secuencia de elementos del alfabeto en secuencia de índices \n",
    "    def __decodify(self, x):\n",
    "        x = list(map(str.upper, x))\n",
    "        try:\n",
    "            decoded= np.array(list(map(self.alphabet.index, x)), dtype=int)\n",
    "        except ValueError:\n",
    "            print(\"¡Error, existe elemento de la secuencia que no se encuentra en el alfabeto!\")\n",
    "            raise\n",
    "        return decoded\n",
    "    \n",
    "    def __codify(self, sequence):\n",
    "        coded_seq = ['M' if elem==0 else 'D' if elem==1 else 'I' for elem in sequence ]\n",
    "        return coded_seq\n",
    "\n",
    "    '''Devuelve true si se trata de una región de inserción'''\n",
    "    def __default_insertion_criteria(self, region):\n",
    "        return region.count(self.gap) > (len(region))/2 or max([region.count(elem) for elem in self.alphabet])<(len(region))/2\n",
    "    \n",
    "    def __laplace_rule(self, row):\n",
    "        row = row + 1\n",
    "        return row*1/np.sum(row)\n",
    "\n",
    "    def __detect_state(self, element, prev_state, in_insert_region):\n",
    "        #Los estados son: 0=M, 1=D, 2=I, 3=I_gap. Éste último sirve para distinguir las inserciones y los gaps de la región de inserción para no acumular erróneamente\n",
    "        state = prev_state\n",
    "\n",
    "        if in_insert_region:\n",
    "            if element!=self.gap:\n",
    "                state = states.I.value\n",
    "            elif (prev_state==states.I.value or prev_state==states.I_gap.value) and element==self.gap:\n",
    "                state = states.I_gap.value\n",
    "        elif not in_insert_region:\n",
    "            if element==self.gap:\n",
    "                state = states.D.value\n",
    "            else:\n",
    "                state = states.M.value\n",
    "\n",
    "        return state\n",
    "    \n",
    "    def __compute_probabilities(self, alignment, regions, insert_regions, emission_pseudocounts, transition_pseudocounts):\n",
    "        match_emissions = np.zeros((self.n_match_states, len(self.alphabet)), dtype=int)\n",
    "        insert_emissions = np.zeros((self.n_match_states+1, len(self.alphabet)), dtype=int)\n",
    "        transition_frenquencies = np.zeros((3, 3, self.n_match_states), dtype=int)\n",
    "        final_transitions = np.zeros((3,2),dtype=int)\n",
    "\n",
    "        region_index = 0\n",
    "        n_sequence = len(alignment)\n",
    "        previous_states = []\n",
    "        actual_states = []\n",
    "\n",
    "        for i in range(len(insert_regions)):\n",
    "\n",
    "            #Caso especial para el primero\n",
    "            if i==0:\n",
    "                gaps = regions[i].count(self.gap)\n",
    "\n",
    "                if not insert_regions[i]:\n",
    "                    transition_frenquencies[states.M.value, states.M.value, region_index] = n_sequence-gaps\n",
    "                    transition_frenquencies[states.M.value, states.D.value, region_index] = gaps\n",
    "                    match_emissions[region_index] = [regions[i].count(elem) for elem in self.alphabet]\n",
    "\n",
    "                    region_index += 1\n",
    "                else:\n",
    "                    insert_emissions[region_index] = np.add(insert_emissions[region_index], [regions[i].count(elem) for elem in self.alphabet])\n",
    "                    transition_frenquencies[states.M.value, states.I.value, region_index] = n_sequence-gaps\n",
    "\n",
    "                previous_states = [self.__detect_state(regions[i][j], 0 ,insert_regions[i]) for j in range(n_sequence)]\n",
    "                \n",
    "            else:\n",
    "                actual_states = [self.__detect_state(regions[i][j], previous_states[j] ,insert_regions[i]) for j in range(n_sequence)]\n",
    "\n",
    "                #Si estamos salimos de región de inserción, cambiamos los I_gap por I\n",
    "                if not insert_regions[i] and insert_regions[i-1]:\n",
    "                    previous_states = [states.I.value if elem==states.I_gap.value else elem for elem in previous_states]\n",
    "\n",
    "                transitions = list(zip(previous_states, actual_states))\n",
    "\n",
    "                if not insert_regions[i]:\n",
    "                    match_emissions[region_index] = [regions[i].count(elem) for elem in self.alphabet]\n",
    "\n",
    "                    for k in range(3):\n",
    "                        transition_frenquencies[k,states.M.value,region_index] = transitions.count((k,states.M.value))\n",
    "                        transition_frenquencies[k,states.D.value,region_index] = transitions.count((k,states.D.value))\n",
    "\n",
    "                    region_index += 1\n",
    "                else:\n",
    "                    insert_emissions[region_index] = np.add(insert_emissions[region_index], [regions[i].count(elem) for elem in self.alphabet])\n",
    "\n",
    "                    for k in range(3):\n",
    "                        transition_frenquencies[k,states.I.value,region_index] += transitions.count((k,states.I.value))\n",
    "\n",
    "                    if insert_regions[i-1]:\n",
    "                        #Tener en cuenta también transiciones de I_gap a I\n",
    "                        transition_frenquencies[states.I.value, states.I.value,region_index] += transitions.count((states.I_gap.value, states.I.value))\n",
    "\n",
    "                previous_states = actual_states\n",
    "\n",
    "        #Calcular probabilidades de transición hasta fin\n",
    "        if insert_regions[-1]:\n",
    "            final_transitions[states.I.value,states.M.value] = actual_states.count(states.I.value)\n",
    "        else:\n",
    "            final_transitions[states.M.value,states.M.value] = actual_states.count(states.M.value)\n",
    "            final_transitions[states.D.value,states.M.value] = actual_states.count(states.D.value)\n",
    "\n",
    "        if not callable(emission_pseudocounts):\n",
    "            match_emissions_pr = np.array(list(map(self.__laplace_rule, match_emissions)))\n",
    "            insert_emissions_pr = np.array(list(map(self.__laplace_rule, insert_emissions)))\n",
    "        else:\n",
    "            match_emissions_pr = np.array(list(map(emission_pseudocounts, match_emissions)))\n",
    "            insert_emissions_pr = np.array(list(map(emission_pseudocounts, insert_emissions)))\n",
    "\n",
    "        if not callable(transition_pseudocounts):\n",
    "            transition_pr = np.apply_along_axis(self.__laplace_rule, 1 ,transition_frenquencies)\n",
    "            final_pr = np.array(list(map(self.__laplace_rule, final_transitions)))\n",
    "        else:\n",
    "            transition_pr = np.apply_along_axis(transition_pseudocounts, 1 ,transition_frenquencies)\n",
    "            final_pr = np.array(list(map(transition_pseudocounts, final_transitions)))\n",
    "\n",
    "        return match_emissions_pr, insert_emissions_pr, transition_pr, final_pr\n",
    "    \n",
    "    def modifiedViterbi(self, x):\n",
    "        decoded_x = self.__decodify(x)\n",
    "        n = len(decoded_x)\n",
    "\n",
    "        v = np.zeros((3, self.n_match_states+1, n+1))\n",
    "        pointer = np.zeros((3,self.n_match_states+1, n+1), dtype=int)\n",
    "        v[0,0,0] = 1\n",
    "\n",
    "        #Ignorar el warning de división entre 0 a la hora de calcular log(0)\n",
    "        with np.errstate(divide='ignore'): \n",
    "            log_emissionprob_ =  np.log(self.emissionprob_)\n",
    "            log_transmat_ = np.log(self.transmat_)\n",
    "            v = np.log(v)\n",
    "\n",
    "        delete_position = self.n_match_states+1\n",
    "        v[1,1,0] = v[0,0,0] + log_transmat_[0,delete_position]\n",
    "        pointer[1,1,0] = 0\n",
    "\n",
    "        for j in range(2, self.n_match_states+1):\n",
    "            delete_position = delete_position + 1\n",
    "            v[1,j,0] = v[1,j-1,0] + log_transmat_[delete_position-1, delete_position]\n",
    "            pointer[1,j,0] = 1\n",
    "\n",
    "        for i in range(1, n+1):\n",
    "            current_positions = np.array([0, self.n_match_states, 2*self.n_match_states+1], dtype=int)\n",
    "\n",
    "            v[2,0,i] = log_emissionprob_[current_positions[2], decoded_x[i-1]]+ np.max([v[0,0,i-1]+log_transmat_[current_positions[0], current_positions[2]], v[2,0,i-1]+log_transmat_[current_positions[2], current_positions[2]]])\n",
    "\n",
    "            pointer[2,0,i] = np.argmax([v[0,0,i-1]+log_transmat_[current_positions[0], current_positions[2]], v[2,0,i-1]+log_transmat_[current_positions[2], current_positions[2]]])\n",
    "\n",
    "            for j in range(1, self.n_match_states+1):\n",
    "                current_positions = current_positions + 1\n",
    "                v[0,j,i] = log_emissionprob_[current_positions[0], decoded_x[i-1]]+ np.max([v[0,j-1,i-1]+log_transmat_[current_positions[0]-1, current_positions[0]], v[1,j-1,i-1]+log_transmat_[current_positions[1]-1, current_positions[0]], v[2,j-1,i-1]+log_transmat_[current_positions[2]-1, current_positions[0]]])\n",
    "\n",
    "                pointer[0,j,i] = np.argmax([v[0,j-1,i-1]+log_transmat_[current_positions[0]-1, current_positions[0]], v[1,j-1,i-1]+log_transmat_[current_positions[1]-1, current_positions[0]], v[2,j-1,i-1]+log_transmat_[current_positions[2]-1, current_positions[0]]])\n",
    "\n",
    "                v[1,j,i] = np.max([v[0,j-1,i]+log_transmat_[current_positions[0]-1, current_positions[1]], v[1,j-1,i]+log_transmat_[current_positions[1]-1, current_positions[1]], v[2,j-1,i]+log_transmat_[current_positions[2]-1, current_positions[1]]])\n",
    "\n",
    "                pointer[1,j,i] = np.argmax([v[0,j-1,i]+log_transmat_[current_positions[0]-1, current_positions[1]], v[1,j-1,i]+log_transmat_[current_positions[1]-1, current_positions[1]], v[2,j-1,i]+log_transmat_[current_positions[2]-1, current_positions[1]]])\n",
    "\n",
    "                v[2,j,i] = log_emissionprob_[current_positions[2], decoded_x[i-1]]+ np.max([v[0,j,i-1]+log_transmat_[current_positions[0], current_positions[2]], v[1,j,i-1]+log_transmat_[current_positions[1], current_positions[2]], v[2,j,i-1]+log_transmat_[current_positions[2], current_positions[2]]])\n",
    "\n",
    "                pointer[2,j,i] = np.argmax([v[0,j,i-1]+log_transmat_[current_positions[0], current_positions[2]], v[1,j,i-1]+log_transmat_[current_positions[1], current_positions[2]], v[2,j,i-1]+log_transmat_[current_positions[2], current_positions[2]]])\n",
    "\n",
    "            sequence = [ np.argmax([v[0,self.n_match_states, n], v[1,self.n_match_states, n], v[2,self.n_match_states, n]])]\n",
    "\n",
    "        viterbi_prob = np.max([v[0,self.n_match_states, n]+log_transmat_[current_positions[0],-1], v[1,self.n_match_states, n]+log_transmat_[current_positions[1],-1], v[2,self.n_match_states, n]+log_transmat_[current_positions[2],-1]])\n",
    "        k = n\n",
    "        l = self.n_match_states\n",
    "        while k>0 or l>0:\n",
    "            next_state = pointer[sequence[-1] ,l, k]\n",
    "            if sequence[-1]!=1:\n",
    "                k= k-1\n",
    "            if sequence[-1]!=2:\n",
    "                l = l-1\n",
    "            sequence.append(next_state)\n",
    "\n",
    "        del sequence[-1]\n",
    "        sequence.reverse()\n",
    "\n",
    "        return self.__codify(sequence), np.exp(viterbi_prob)\n",
    "    \n",
    "    def modifiedFoward(self, x):\n",
    "        decoded_x = self.__decodify(x)\n",
    "        n = len(decoded_x)\n",
    "\n",
    "        v = np.zeros((3, self.n_match_states+1, n+1))\n",
    "        v[0,0,0] = 1\n",
    "\n",
    "        #Ignorar el warning de división entre 0 a la hora de calcular log(0)\n",
    "        with np.errstate(divide='ignore'): \n",
    "            log_emissionprob_ =  np.log(self.emissionprob_)\n",
    "            log_transmat_ = np.log(self.transmat_)\n",
    "            v = np.log(v)\n",
    "\n",
    "        delete_position = self.n_match_states+1\n",
    "        v[1,1,0] = v[0,0,0] + log_transmat_[0,delete_position]\n",
    "\n",
    "        for j in range(2, self.n_match_states+1):\n",
    "            delete_position = delete_position + 1\n",
    "            v[1,j,0] = v[1,j-1,0] + log_transmat_[delete_position-1, delete_position]\n",
    "\n",
    "        for i in range(1, n+1):\n",
    "            current_positions = np.array([0, self.n_match_states, 2*self.n_match_states+1], dtype=int)\n",
    "\n",
    "            v[2,0,i] = log_emissionprob_[current_positions[2], decoded_x[i-1]]+ special.logsumexp([v[0,0,i-1]+log_transmat_[current_positions[0], current_positions[2]], v[2,0,i-1]+log_transmat_[current_positions[2], current_positions[2]]])\n",
    "\n",
    "            for j in range(1, self.n_match_states+1):\n",
    "                current_positions = current_positions + 1\n",
    "\n",
    "                v[0,j,i] = log_emissionprob_[current_positions[0], decoded_x[i-1]]+special.logsumexp([v[0,j-1,i-1]+log_transmat_[current_positions[0]-1, current_positions[0]], v[1,j-1,i-1]+log_transmat_[current_positions[1]-1, current_positions[0]], v[2,j-1,i-1]+log_transmat_[current_positions[2]-1, current_positions[0]]])\n",
    "\n",
    "                v[1,j,i] = special.logsumexp([v[0,j-1,i]+log_transmat_[current_positions[0]-1, current_positions[1]], v[1,j-1,i]+log_transmat_[current_positions[1]-1, current_positions[1]], v[2,j-1,i]+log_transmat_[current_positions[2]-1, current_positions[1]]])\n",
    "\n",
    "                v[2,j,i] = log_emissionprob_[current_positions[2], decoded_x[i-1]]+ special.logsumexp([v[0,j,i-1]+log_transmat_[current_positions[0], current_positions[2]], v[1,j,i-1]+log_transmat_[current_positions[1], current_positions[2]], v[2,j,i-1]+log_transmat_[current_positions[2], current_positions[2]]])\n",
    "\n",
    "\n",
    "        v_fin = special.logsumexp([v[0,self.n_match_states, n]+log_transmat_[current_positions[0],-1], v[1,self.n_match_states, n]+log_transmat_[current_positions[1],-1], v[2,self.n_match_states, n]+log_transmat_[current_positions[2],-1]])\n",
    "\n",
    "        return np.exp(v_fin)\n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejemplos: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilidades de emisión de estados de alineamiento:\n",
      " [[0.14285714 0.14285714 0.14285714 0.57142857]\n",
      " [0.625      0.125      0.125      0.125     ]\n",
      " [0.14285714 0.14285714 0.57142857 0.14285714]\n",
      " [0.14285714 0.14285714 0.14285714 0.57142857]\n",
      " [0.125      0.5        0.25       0.125     ]]\n",
      "Probabilidades de emisión de estados de inserción:\n",
      " [[0.25 0.25 0.25 0.25]\n",
      " [0.25 0.25 0.25 0.25]\n",
      " [0.25 0.25 0.25 0.25]\n",
      " [0.4  0.2  0.2  0.2 ]\n",
      " [0.25 0.25 0.25 0.25]\n",
      " [0.25 0.25 0.25 0.25]]\n",
      "Probabilidades de transición entre estados:\n",
      " [[[0.57142857 0.66666667 0.57142857 0.5        0.66666667]\n",
      "  [0.28571429 0.16666667 0.28571429 0.16666667 0.16666667]\n",
      "  [0.14285714 0.16666667 0.14285714 0.33333333 0.16666667]]\n",
      "\n",
      " [[0.33333333 0.5        0.33333333 0.5        0.5       ]\n",
      "  [0.33333333 0.25       0.33333333 0.25       0.25      ]\n",
      "  [0.33333333 0.25       0.33333333 0.25       0.25      ]]\n",
      "\n",
      " [[0.33333333 0.33333333 0.33333333 0.25       0.33333333]\n",
      "  [0.33333333 0.33333333 0.33333333 0.5        0.33333333]\n",
      "  [0.33333333 0.33333333 0.33333333 0.25       0.33333333]]]\n",
      "Probabilidades de transición al estado fin:\n",
      " [[0.83333333 0.16666667]\n",
      " [0.5        0.5       ]\n",
      " [0.5        0.5       ]]\n"
     ]
    }
   ],
   "source": [
    "model = ProfileHMM(alphabet=[\"A\", \"C\", \"G\", \"T\"], gap_symbol='-', alignment=['TA--TC', 'TAG-TC', 'TAGA-C', '-AG-TG'], show_probabilities=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'M', 'M', 'I', 'M', 'M', 'M']\n"
     ]
    }
   ],
   "source": [
    "x = \"ATATGTC\"\n",
    "result, prob = model.modifiedViterbi(x)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.393704882159438e-05\n"
     ]
    }
   ],
   "source": [
    "total_prob=model.modifiedFoward(x)\n",
    "print(total_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['D', 'M', 'D', 'M', 'M']\n"
     ]
    }
   ],
   "source": [
    "x = \"ATC\"\n",
    "result, prob = model.modifiedViterbi(x)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.004601382312893029\n"
     ]
    }
   ],
   "source": [
    "total_prob=model.modifiedFoward(x)\n",
    "print(total_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['D', 'M', 'D', 'M', 'M']\n"
     ]
    }
   ],
   "source": [
    "y = \"AAC\"\n",
    "result, prob = model.modifiedViterbi(y)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.003040138977867695\n"
     ]
    }
   ],
   "source": [
    "total_prob=model.modifiedFoward(y)\n",
    "print(total_prob)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
